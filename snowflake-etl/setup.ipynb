{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74f686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the project root is in the Python path\n",
    "import sys\n",
    "sys.path.append('/Users/tl759k/Documents/GitHub/work/cursor-analytics')\n",
    "\n",
    "# Activate the virtual environment (if not already activated)\n",
    "# This is typically done outside the notebook, but we ensure the path is correct here\n",
    "import os\n",
    "os.system('source /Users/tl759k/Documents/GitHub/work/cursor-analytics/venv/bin/activate')\n",
    "\n",
    "# Re-import the SnowflakeHook after ensuring the path is set\n",
    "from utils.snowflake_connection import SnowflakeHook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from decimal import Decimal\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# Load and execute SQL queries for data jobs (no data return)\n",
    "def execute_sql_job(file_path):\n",
    "    \"\"\"\n",
    "    Execute SQL statements from a file for table refresh/creation jobs.\n",
    "    Handles multiple statements (CREATE TABLE, GRANT, etc.) without returning data.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to SQL file containing statements\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if all statements executed successfully\n",
    "    \"\"\"\n",
    "    import time\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    # Start overall timer\n",
    "    overall_start_time = time.time()\n",
    "    start_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    print(f\"üîÑ Starting SQL job from: {file_path}\")\n",
    "    print(f\"‚è∞ Start time: {start_timestamp}\")\n",
    "    \n",
    "    # Read SQL file\n",
    "    with open(file_path, 'r') as file:\n",
    "        query_content = file.read()\n",
    "    \n",
    "    # Initialize Snowflake connection with larger warehouse for better performance\n",
    "    connection_start = time.time()\n",
    "    snowhook = SnowflakeHook(\n",
    "        warehouse='DCR_WH_4XLARGE'  # Use 4XL warehouse for fastest performance\n",
    "    )\n",
    "    connection_time = time.time() - connection_start\n",
    "    print(f\"‚úÖ Connected to Snowflake with DCR_WH_4XLARGE warehouse (took {connection_time:.2f}s)\")\n",
    "    \n",
    "    # Split SQL statements by semicolon and execute each one\n",
    "    statements = [stmt.strip() for stmt in query_content.split(';') if stmt.strip()]\n",
    "    total_statements = len(statements)\n",
    "    \n",
    "    print(f\"üìã Found {total_statements} SQL statement(s) to execute\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    statement_times = []\n",
    "    \n",
    "    try:\n",
    "        for i, statement in enumerate(statements, 1):\n",
    "            # Calculate progress\n",
    "            progress_pct = ((i-1) / total_statements) * 100\n",
    "            \n",
    "            # Estimate time remaining based on average of completed statements\n",
    "            if len(statement_times) > 0:\n",
    "                avg_time = sum(statement_times) / len(statement_times)\n",
    "                remaining_statements = total_statements - (i-1)\n",
    "                estimated_remaining = avg_time * remaining_statements\n",
    "                eta_str = f\" | ETA: {estimated_remaining:.1f}s\"\n",
    "            else:\n",
    "                eta_str = \"\"\n",
    "            \n",
    "            print(f\"üîÑ [{progress_pct:5.1f}%] Statement {i}/{total_statements}{eta_str}\")\n",
    "            print(f\"   üìù Preview: {statement[:80]}{'...' if len(statement) > 80 else ''}\")\n",
    "            \n",
    "            # Execute statement with timing\n",
    "            stmt_start_time = time.time()\n",
    "            snowhook.query_without_result(statement)\n",
    "            stmt_duration = time.time() - stmt_start_time\n",
    "            statement_times.append(stmt_duration)\n",
    "            \n",
    "            # Update progress\n",
    "            progress_pct = (i / total_statements) * 100\n",
    "            print(f\"   ‚úÖ Completed in {stmt_duration:.2f}s [{progress_pct:5.1f}%]\")\n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        # Final timing summary\n",
    "        total_duration = time.time() - overall_start_time\n",
    "        end_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        print(f\"üéâ All {total_statements} statements executed successfully!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üìä TIMING SUMMARY:\")\n",
    "        print(f\"   ‚Ä¢ Start time: {start_timestamp}\")\n",
    "        print(f\"   ‚Ä¢ End time: {end_timestamp}\")\n",
    "        print(f\"   ‚Ä¢ Total duration: {total_duration:.2f}s ({total_duration/60:.2f} minutes)\")\n",
    "        print(f\"   ‚Ä¢ Connection time: {connection_time:.2f}s\")\n",
    "        print(f\"   ‚Ä¢ Average per statement: {sum(statement_times)/len(statement_times):.2f}s\")\n",
    "        print(f\"   ‚Ä¢ Fastest statement: {min(statement_times):.2f}s\")\n",
    "        print(f\"   ‚Ä¢ Slowest statement: {max(statement_times):.2f}s\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        total_duration = time.time() - overall_start_time\n",
    "        end_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        print(f\"‚ùå Error executing SQL job: {str(e)}\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"‚ö†Ô∏è JOB FAILED AFTER {total_duration:.2f}s\")\n",
    "        print(f\"   ‚Ä¢ Failed at statement {i}/{total_statements}\")\n",
    "        print(f\"   ‚Ä¢ Completed statements: {i-1}\")\n",
    "        if statement_times:\n",
    "            print(f\"   ‚Ä¢ Average time per completed statement: {sum(statement_times)/len(statement_times):.2f}s\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Keep the original function for data retrieval (single statement only)\n",
    "def load_query(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a single SQL SELECT statement.\n",
    "    Use this for queries that return data you want to analyze.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to SQL file with single SELECT statement\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Query results as DataFrame\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        query = file.read()\n",
    "    \n",
    "    snowhook = SnowflakeHook(\n",
    "        warehouse='DCR_WH_4XLARGE'  # Use 4XL warehouse for better performance\n",
    "    )\n",
    "    df = snowhook.query_snowflake(query, method='pandas')\n",
    "\n",
    "    # Format decimal to float\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # Check if column has any non-null values before checking type\n",
    "            non_null_values = df[col].dropna()\n",
    "            if len(non_null_values) > 0 and isinstance(non_null_values.iloc[0], Decimal):\n",
    "                df[col] = df[col].astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45650c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Enhanced SQL job functions loaded!\n",
      "üí° Use execute_sql_job_with_progress_bar('test.sql') for visual progress tracking\n"
     ]
    }
   ],
   "source": [
    "# Helper function to create a visual progress bar\n",
    "def create_progress_bar(percentage, width=30):\n",
    "    \"\"\"Create a visual progress bar string\"\"\"\n",
    "    filled = int(width * percentage / 100)\n",
    "    bar = \"‚ñà\" * filled + \"‚ñë\" * (width - filled)\n",
    "    return f\"[{bar}] {percentage:5.1f}%\"\n",
    "\n",
    "# Enhanced version with visual progress bar\n",
    "def execute_sql_job_with_progress_bar(file_path):\n",
    "    \"\"\"\n",
    "    Enhanced version with visual progress bar for better monitoring\n",
    "    \"\"\"\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Start overall timer\n",
    "    overall_start_time = time.time()\n",
    "    start_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # print(f\"üîÑ Starting SQL job from: {file_path}\")\n",
    "    # print(f\"‚è∞ Start time: {start_timestamp}\")\n",
    "    \n",
    "    # Read SQL file\n",
    "    with open(file_path, 'r') as file:\n",
    "        query_content = file.read()\n",
    "    \n",
    "    # Initialize Snowflake connection\n",
    "    connection_start = time.time()\n",
    "    snowhook = SnowflakeHook()\n",
    "    connection_time = time.time() - connection_start\n",
    "    # print(f\"‚úÖ Connected to Snowflake (took {connection_time:.2f}s)\")\n",
    "    \n",
    "    # Split SQL statements\n",
    "    statements = [stmt.strip() for stmt in query_content.split(';') if stmt.strip()]\n",
    "    total_statements = len(statements)\n",
    "    \n",
    "    # print(f\"üìã Found {total_statements} SQL statement(s) to execute\")\n",
    "    # print(\"=\" * 70)\n",
    "    \n",
    "    statement_times = []\n",
    "    \n",
    "    try:\n",
    "        for i, statement in enumerate(statements, 1):\n",
    "            # Calculate progress\n",
    "            progress_pct = ((i-1) / total_statements) * 100\n",
    "            \n",
    "            # Create visual progress bar\n",
    "            progress_bar = create_progress_bar(progress_pct)\n",
    "            \n",
    "            # Estimate time remaining\n",
    "            if len(statement_times) > 0:\n",
    "                avg_time = sum(statement_times) / len(statement_times)\n",
    "                remaining_statements = total_statements - (i-1)\n",
    "                estimated_remaining = avg_time * remaining_statements\n",
    "                eta_str = f\"ETA: {estimated_remaining:.1f}s\"\n",
    "            else:\n",
    "                eta_str = \"ETA: calculating...\"\n",
    "            \n",
    "            # print(f\"\\nüîÑ Statement {i}/{total_statements} | {eta_str}\")\n",
    "            # print(f\"   {progress_bar}\")\n",
    "            # print(f\"   üìù {statement[:60]}{'...' if len(statement) > 60 else ''}\")\n",
    "            \n",
    "            # Execute statement with timing\n",
    "            stmt_start_time = time.time()\n",
    "            snowhook.query_without_result(statement)\n",
    "            stmt_duration = time.time() - stmt_start_time\n",
    "            statement_times.append(stmt_duration)\n",
    "            \n",
    "            # Update progress\n",
    "            progress_pct = (i / total_statements) * 100\n",
    "            progress_bar_complete = create_progress_bar(progress_pct)\n",
    "            \n",
    "            print(f\"   ‚úÖ Completed in {stmt_duration:.2f}s\")\n",
    "            print(f\"   {progress_bar_complete}\")\n",
    "        \n",
    "        # Final summary\n",
    "        total_duration = time.time() - overall_start_time\n",
    "        end_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"üéâ ALL STATEMENTS COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"üìä PERFORMANCE SUMMARY:\")\n",
    "        print(f\"   ‚è∞ Duration: {total_duration:.2f}s ({total_duration/60:.2f} min)\")\n",
    "        print(f\"   üîó Connection: {connection_time:.2f}s\")\n",
    "        print(f\"   üìä Avg/statement: {sum(statement_times)/len(statement_times):.2f}s\")\n",
    "        print(f\"   ‚ö° Fastest: {min(statement_times):.2f}s\")\n",
    "        print(f\"   üêå Slowest: {max(statement_times):.2f}s\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        total_duration = time.time() - overall_start_time\n",
    "        print(f\"\\n‚ùå ERROR: {str(e)}\")\n",
    "        print(f\"‚ö†Ô∏è Failed after {total_duration:.2f}s at statement {i}/{total_statements}\")\n",
    "        return False\n",
    "\n",
    "print(\"üì¶ Enhanced SQL job functions loaded!\")\n",
    "print(\"üí° Use execute_sql_job_with_progress_bar('test.sql') for visual progress tracking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8681d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:21:39,907 - utils.snowflake_connection - ERROR - Failed to create optimized Spark session: Java gateway process exited before sending its port number\n",
      "2025-09-22 05:21:39,907 - utils.snowflake_connection - ERROR - Failed to create Spark session: Java gateway process exited before sending its port number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The operation couldn‚Äôt be completed. Unable to locate a Java Runtime.\n",
      "Please visit http://www.java.com for information on installing Java.\n",
      "\n",
      "/Users/tl759k/Documents/GitHub/work/cursor-analytics/venv/lib/python3.11/site-packages/pyspark/bin/spark-class: line 96: CMD: bad array subscript\n",
      "head: illegal line count -- -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:21:40,694 - utils.snowflake_connection - INFO - Successfully connected to Snowflake\n",
      "   ‚úÖ Completed in 456.45s\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]  50.0%\n",
      "   ‚úÖ Completed in 0.16s\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.0%\n",
      "\n",
      "======================================================================\n",
      "üéâ ALL STATEMENTS COMPLETED SUCCESSFULLY!\n",
      "üìä PERFORMANCE SUMMARY:\n",
      "   ‚è∞ Duration: 456.73s (7.61 min)\n",
      "   üîó Connection: 0.12s\n",
      "   üìä Avg/statement: 228.31s\n",
      "   ‚ö° Fastest: 0.16s\n",
      "   üêå Slowest: 456.45s\n"
     ]
    }
   ],
   "source": [
    "step_0 = execute_sql_job_with_progress_bar('s0_tbl_applicant_funnel_timestamp_with_backfill_snowflake.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73938150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:29:16,803 - utils.snowflake_connection - ERROR - Failed to create optimized Spark session: Java gateway process exited before sending its port number\n",
      "2025-09-22 05:29:16,804 - utils.snowflake_connection - ERROR - Failed to create Spark session: Java gateway process exited before sending its port number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The operation couldn‚Äôt be completed. Unable to locate a Java Runtime.\n",
      "Please visit http://www.java.com for information on installing Java.\n",
      "\n",
      "/Users/tl759k/Documents/GitHub/work/cursor-analytics/venv/lib/python3.11/site-packages/pyspark/bin/spark-class: line 96: CMD: bad array subscript\n",
      "head: illegal line count -- -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:29:17,657 - utils.snowflake_connection - INFO - Successfully connected to Snowflake\n",
      "   ‚úÖ Completed in 209.53s\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]  50.0%\n",
      "   ‚úÖ Completed in 0.17s\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.0%\n",
      "\n",
      "======================================================================\n",
      "üéâ ALL STATEMENTS COMPLETED SUCCESSFULLY!\n",
      "üìä PERFORMANCE SUMMARY:\n",
      "   ‚è∞ Duration: 209.96s (3.50 min)\n",
      "   üîó Connection: 0.26s\n",
      "   üìä Avg/statement: 104.85s\n",
      "   ‚ö° Fastest: 0.17s\n",
      "   üêå Slowest: 209.53s\n"
     ]
    }
   ],
   "source": [
    "step_1 = execute_sql_job_with_progress_bar('s1_tbl_major_steps_conversion_analysis_applied_L7D_cohort_snowflake.sql')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "757c56df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:32:46,645 - utils.snowflake_connection - ERROR - Failed to create optimized Spark session: Java gateway process exited before sending its port number\n",
      "2025-09-22 05:32:46,646 - utils.snowflake_connection - ERROR - Failed to create Spark session: Java gateway process exited before sending its port number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The operation couldn‚Äôt be completed. Unable to locate a Java Runtime.\n",
      "Please visit http://www.java.com for information on installing Java.\n",
      "\n",
      "/Users/tl759k/Documents/GitHub/work/cursor-analytics/venv/lib/python3.11/site-packages/pyspark/bin/spark-class: line 96: CMD: bad array subscript\n",
      "head: illegal line count -- -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:32:47,239 - utils.snowflake_connection - INFO - Successfully connected to Snowflake\n",
      "   ‚úÖ Completed in 17.54s\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]  50.0%\n",
      "   ‚úÖ Completed in 0.17s\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.0%\n",
      "\n",
      "======================================================================\n",
      "üéâ ALL STATEMENTS COMPLETED SUCCESSFULLY!\n",
      "üìä PERFORMANCE SUMMARY:\n",
      "   ‚è∞ Duration: 17.84s (0.30 min)\n",
      "   üîó Connection: 0.13s\n",
      "   üìä Avg/statement: 8.86s\n",
      "   ‚ö° Fastest: 0.17s\n",
      "   üêå Slowest: 17.54s\n"
     ]
    }
   ],
   "source": [
    "step_2 = execute_sql_job_with_progress_bar('s2_tbl_cvr_reporting_metric_variances_snowflake.sql')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c14864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:33:04,492 - utils.snowflake_connection - ERROR - Failed to create optimized Spark session: Java gateway process exited before sending its port number\n",
      "2025-09-22 05:33:04,492 - utils.snowflake_connection - ERROR - Failed to create Spark session: Java gateway process exited before sending its port number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The operation couldn‚Äôt be completed. Unable to locate a Java Runtime.\n",
      "Please visit http://www.java.com for information on installing Java.\n",
      "\n",
      "/Users/tl759k/Documents/GitHub/work/cursor-analytics/venv/lib/python3.11/site-packages/pyspark/bin/spark-class: line 96: CMD: bad array subscript\n",
      "head: illegal line count -- -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:33:05,151 - utils.snowflake_connection - INFO - Successfully connected to Snowflake\n",
      "   ‚úÖ Completed in 47.11s\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]  50.0%\n",
      "   ‚úÖ Completed in 0.17s\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.0%\n",
      "\n",
      "======================================================================\n",
      "üéâ ALL STATEMENTS COMPLETED SUCCESSFULLY!\n",
      "üìä PERFORMANCE SUMMARY:\n",
      "   ‚è∞ Duration: 47.40s (0.79 min)\n",
      "   üîó Connection: 0.12s\n",
      "   üìä Avg/statement: 23.64s\n",
      "   ‚ö° Fastest: 0.17s\n",
      "   üêå Slowest: 47.11s\n"
     ]
    }
   ],
   "source": [
    "step_3 = execute_sql_job_with_progress_bar('s3_tbl_conversion_funnel_idv_substeps_all_timestamps_snowflake.sql')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
