{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Core Zipcodes by Municipal Boundary (TIGER/Line + ZCTA)\n",
        "\n",
        "This notebook produces core ZIP codes (ZCTAs) whose centroids fall strictly within each city's municipal boundary using US Census TIGER/Line Place polygons and ZCTA polygons.\n",
        "\n",
        "- Input: `top_100_cities.csv`\n",
        "- Output: `top_100_cities_core_zipcodes.csv` (ZIPCODES column added)\n",
        "- Method: Spatial join of ZCTA centroids within Place polygons (incorporated/consolidated places)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from shapely.ops import unary_union\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATA_DIR = 'data_tiger'\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "print('Env ready')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cities list\n",
        "cities = pd.read_csv('top_100_cities.csv')\n",
        "# Normalize\n",
        "cities['CITY_NORM'] = cities['CITY'].str.upper().str.replace('\\.', '', regex=False).str.strip()\n",
        "cities['STATE_NORM'] = cities['STATE'].str.upper().str.strip()\n",
        "print(cities.head(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Census cartographic boundary shapefiles (stable URLs)\n",
        "# Places (2023, 1:500k) and ZCTA5 (2020, 1:500k)\n",
        "places_url = 'https://www2.census.gov/geo/tiger/GENZ2023/shp/cb_2023_us_place_500k.zip'\n",
        "zcta_url = 'https://www2.census.gov/geo/tiger/GENZ2020/shp/cb_2020_us_zcta520_500k.zip'\n",
        "\n",
        "places_zip = os.path.join(DATA_DIR, 'cb_2023_us_place_500k.zip')\n",
        "zcta_zip = os.path.join(DATA_DIR, 'cb_2020_us_zcta520_500k.zip')\n",
        "\n",
        "# Download if missing\n",
        "import urllib.request\n",
        "for url, dest in [(places_url, places_zip), (zcta_url, zcta_zip)]:\n",
        "    if not os.path.exists(dest):\n",
        "        print('Downloading', url)\n",
        "        urllib.request.urlretrieve(url, dest)\n",
        "        print('Saved to', dest)\n",
        "    else:\n",
        "        print('Exists', dest)\n",
        "\n",
        "# Unzip\n",
        "import zipfile\n",
        "for dest in [places_zip, zcta_zip]:\n",
        "    with zipfile.ZipFile(dest, 'r') as zf:\n",
        "        zf.extractall(DATA_DIR)\n",
        "print('Unzipped')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load geodata\n",
        "place_fp = [f for f in os.listdir(DATA_DIR) if f.startswith('cb_2023_us_place_500k') and f.endswith('.shp')][0]\n",
        "zcta_fp = [f for f in os.listdir(DATA_DIR) if f.startswith('cb_2020_us_zcta520_500k') and f.endswith('.shp')][0]\n",
        "\n",
        "places = gpd.read_file(os.path.join(DATA_DIR, place_fp))\n",
        "zctas = gpd.read_file(os.path.join(DATA_DIR, zcta_fp))\n",
        "\n",
        "# Normalize columns\n",
        "places['NAME_NORM'] = places['NAME'].str.upper().str.replace('\\.', '', regex=False)\n",
        "# In cartographic shapefiles, state FIPS is in STATEFP\n",
        "places['STATEFP'] = places['STATEFP']\n",
        "\n",
        "# ZCTA code column could be ZCTA5CE10 or ZCTA5CE20; detect\n",
        "zcta_col = 'ZCTA5CE10' if 'ZCTA5CE10' in zctas.columns else ('ZCTA5CE20' if 'ZCTA5CE20' in zctas.columns else None)\n",
        "if zcta_col is None:\n",
        "    raise RuntimeError(f'ZCTA code column not found. Columns: {list(zctas.columns)}')\n",
        "zctas[zcta_col] = zctas[zcta_col].astype(str)\n",
        "\n",
        "print(len(places), 'places;', len(zctas), 'zctas')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map state abbreviations to FIPS\n",
        "state_abbr_to_fips = {\n",
        "    'AL':'01','AK':'02','AZ':'04','AR':'05','CA':'06','CO':'08','CT':'09','DE':'10','DC':'11','FL':'12','GA':'13','HI':'15','ID':'16','IL':'17','IN':'18','IA':'19','KS':'20','KY':'21','LA':'22','ME':'23','MD':'24','MA':'25','MI':'26','MN':'27','MS':'28','MO':'29','MT':'30','NE':'31','NV':'32','NH':'33','NJ':'34','NM':'35','NY':'36','NC':'37','ND':'38','OH':'39','OK':'40','OR':'41','PA':'42','RI':'44','SC':'45','SD':'46','TN':'47','TX':'48','UT':'49','VT':'50','VA':'51','WA':'53','WV':'54','WI':'55','WY':'56'}\n",
        "\n",
        "# Build lookup on places by (name,state)\n",
        "places['KEY'] = places['NAME_NORM'] + '|' + places['STATEFP']\n",
        "\n",
        "print('Prepared place keys')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute ZCTA centroids in same CRS as places\n",
        "if zctas.crs != places.crs:\n",
        "    zctas = zctas.to_crs(places.crs)\n",
        "\n",
        "zcta_centroids = zctas.copy()\n",
        "zcta_centroids['geometry'] = zcta_centroids.geometry.centroid\n",
        "\n",
        "# Track the chosen ZCTA code column across the notebook\n",
        "zcta_code_col = zcta_col\n",
        "\n",
        "print('Prepared centroids')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For each city, find matching place(s) and collect ZCTAs whose centroids fall within\n",
        "core_rows = []\n",
        "\n",
        "for _, r in tqdm(cities.iterrows(), total=len(cities)):\n",
        "    city_name = r['CITY_NORM']\n",
        "    state_abbr = r['STATE_NORM']\n",
        "    statefp = state_abbr_to_fips.get(state_abbr)\n",
        "    if statefp is None:\n",
        "        core_rows.append({**r.to_dict(), 'ZIPCODES': ''})\n",
        "        continue\n",
        "    # Some city names may include qualifiers like \"St. Louis\" vs \"Saint Louis\"\n",
        "    name_variants = {city_name,\n",
        "                     city_name.replace('ST ', 'SAINT '),\n",
        "                     city_name.replace('SAINT ', 'ST ')}\n",
        "\n",
        "    candidate_places = places[places['STATEFP'] == statefp]\n",
        "    candidate_places = candidate_places[candidate_places['NAME_NORM'].isin(name_variants)]\n",
        "\n",
        "    if candidate_places.empty:\n",
        "        # fallback: contains\n",
        "        candidate_places = places[(places['STATEFP'] == statefp) & (places['NAME_NORM'].str.contains(city_name, regex=False))]\n",
        "\n",
        "    if candidate_places.empty:\n",
        "        core_rows.append({**r.to_dict(), 'ZIPCODES': ''})\n",
        "        continue\n",
        "\n",
        "    # Union geometry if multiple place parts\n",
        "    union_geom = candidate_places.unary_union\n",
        "\n",
        "    # Select ZCTAs whose centroid is within place polygon\n",
        "    within_mask = zcta_centroids.within(union_geom)\n",
        "    zips = zcta_centroids.loc[within_mask, zcta_code_col].tolist()\n",
        "    zips_sorted = sorted(set(zips))\n",
        "\n",
        "    rec = r.to_dict()\n",
        "    rec['ZIPCODES'] = ','.join(zips_sorted)\n",
        "    core_rows.append(rec)\n",
        "\n",
        "core_df = pd.DataFrame(core_rows)\n",
        "print('Done cities:', len(core_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save output in requested format\n",
        "output = core_df[['CITY_STATE','CITY','STATE','POPULATION','CITY_RANK']].copy()\n",
        "output['ZIPCODES'] = core_df['ZIPCODES']\n",
        "output.to_csv('top_100_cities_core_zipcodes.csv', index=False)\n",
        "print('Wrote top_100_cities_core_zipcodes.csv')\n",
        "\n",
        "# Quick spot checks\n",
        "for city in ['Tampa', 'Orlando', 'Miami']:\n",
        "    row = output[output['CITY'] == city]\n",
        "    if not row.empty:\n",
        "        print(city, '->', row.iloc[0]['ZIPCODES'][:120] + ('...' if len(row.iloc[0]['ZIPCODES'])>120 else ''))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create long-form CSV with one zipcode per row\n",
        "import pandas as pd\n",
        "\n",
        "wide_df = pd.read_csv('top_100_cities_core_zipcodes.csv')\n",
        "wide_df['ZIPCODES'] = wide_df['ZIPCODES'].fillna('')\n",
        "\n",
        "# Split comma-separated zipcodes and explode to rows\n",
        "long_df = wide_df.assign(ZIPCODE=wide_df['ZIPCODES'].str.split(',')).explode('ZIPCODE')\n",
        "long_df['ZIPCODE'] = long_df['ZIPCODE'].astype(str).str.strip()\n",
        "long_df = long_df[long_df['ZIPCODE'] != '']\n",
        "\n",
        "# Keep requested columns\n",
        "long_df = long_df[['CITY_STATE','CITY','STATE','POPULATION','CITY_RANK','ZIPCODE']]\n",
        "\n",
        "# Save\n",
        "long_out = 'top_100_cities_core_zipcodes_long.csv'\n",
        "long_df.to_csv(long_out, index=False)\n",
        "print('Wrote', long_out, 'rows:', len(long_df))\n",
        "\n",
        "# Quick peek\n",
        "print(long_df.head(10).to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
